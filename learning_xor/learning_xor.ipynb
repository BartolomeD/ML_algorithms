{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Learning\n",
    "\n",
    "As can be seen in the figure below, XOR could be framed as a non-linear binary classification problem. Linear models, such as logistic regression or even single layer neural networks, will not be able to find a solution. We need to introduce nonlinearity by using multiple neural network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANAAAADFCAYAAAAlv3xcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f02a20470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "ax.scatter(0, 0, c='r', label='False')\n",
    "ax.scatter(1, 1, c='r')\n",
    "ax.scatter(1, 0, c='b', label='True')\n",
    "ax.scatter(0, 1, c='b')\n",
    "legend = ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression cannot find a solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_score(true, pred):\n",
    "    return sum(map(lambda x, y: 1 if x == y else 0, true, pred)) / len(true)\n",
    "\n",
    "x = [[0,0], [1,1], [1,0], [0,1]]\n",
    "y = [0, 0, 1, 1]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x, y)\n",
    "preds = model.predict(x)\n",
    "\n",
    "accuracy_score(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with PyTorch\n",
    "\n",
    "Learns XOR using a small neural network in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10000 -- loss: 0.0008"
     ]
    }
   ],
   "source": [
    "# neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.sigmoid(self.layer2(x))\n",
    "        return x\n",
    "    \n",
    "    def train(self, data_loader, optimizer, loss_fn):\n",
    "        for i, (inputs, targets) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('\\rBatch: {} -- loss: {}'.format(i+1, format(loss.data[0], '.4f')), end='')\n",
    "\n",
    "# data loader\n",
    "def data_generator(x_train, y_train, n_batch, batch_size):\n",
    "    for _ in range(n_batch):\n",
    "        x = np.array([])\n",
    "        y = np.array([])\n",
    "        for _ in range(batch_size):\n",
    "            r = np.random.randint(0, 4)\n",
    "            x = np.append(x, x_train[r])\n",
    "            y = np.append(y, y_train[r])\n",
    "        x = Variable(torch.from_numpy(x.reshape(-1, 2))).float()\n",
    "        y = Variable(torch.from_numpy(y)).float()\n",
    "        yield x, y\n",
    "        \n",
    "def one_hot_encode(n_class, x):\n",
    "    return np.array(list(map(lambda i: np.eye(n_class)[i], x)))\n",
    "\n",
    "x = np.array(x)\n",
    "y_ohe = one_hot_encode(2, y)\n",
    "\n",
    "# hyperparameters\n",
    "input_size = x.shape[1]\n",
    "hidden_size = 3\n",
    "output_size = y_ohe.shape[1]\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "n_batch = 10000\n",
    "\n",
    "# instantiate model\n",
    "model = Net(input_size, hidden_size, output_size)\n",
    "\n",
    "# set loss function, optimizer and data_loader\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "data_loader = data_generator(x, y_ohe, n_batch, batch_size)\n",
    "\n",
    "# train model\n",
    "model.train(data_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with Numpy\n",
    "\n",
    "Uses weights from trained PyTorch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, False]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get weights and biases from trained model\n",
    "params = model.state_dict()\n",
    "W = [params[w].numpy() for w in ['layer1.weight', 'layer2.weight']]\n",
    "b = [params[b].numpy() for b in ['layer1.bias', 'layer2.bias']]\n",
    "\n",
    "# sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return list(map(lambda i: 1/(1+np.exp(i)), x))\n",
    "\n",
    "# relu activation function\n",
    "def relu(x):\n",
    "    return list(map(lambda i: 0 if i <= 0 else i, x))\n",
    "\n",
    "# neural network with same architecture as PyTorch one\n",
    "def neural_net(inputs):\n",
    "    return list(map(lambda x: sigmoid(W[1] @ relu(W[0] @ x + b[0]) + b[1]), inputs))\n",
    "\n",
    "# test if XOR\n",
    "def is_XOR(inputs):\n",
    "    outputs = neural_net(inputs)\n",
    "    return list(map(lambda x: True if np.argmax(x) == 0 else False, outputs))\n",
    "\n",
    "is_XOR([[1,0],  # TRUE\n",
    "        [0,1],  # TRUE\n",
    "        [0,0],  # FALSE\n",
    "        [1,1]]) # FALSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visualizing the output of the first layer, we see that the neural network first maps the data to a linear problem, after which the second layer is able to find a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANAAAADFCAYAAAAlv3xcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f02aab128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# neural network returning the hidden layer output\n",
    "def neural_net_hidden(inputs):\n",
    "    return list(map(lambda x: relu(W[0] @ x + b[0]), inputs))\n",
    "\n",
    "hidden_out = neural_net_hidden(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "ax.scatter(hidden_out[0][0], hidden_out[0][1], c='r', label='False')\n",
    "ax.scatter(hidden_out[1][0], hidden_out[1][1], c='r')\n",
    "ax.scatter(hidden_out[2][0], hidden_out[2][1], c='b', label='True')\n",
    "ax.scatter(hidden_out[3][0], hidden_out[3][1], c='b')\n",
    "legend = ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, any linear model will be able to find a solution now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(hidden_out, y)\n",
    "preds = model.predict(hidden_out)\n",
    "\n",
    "accuracy_score(y, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
